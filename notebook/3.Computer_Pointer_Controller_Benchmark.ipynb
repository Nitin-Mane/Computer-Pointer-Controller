{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Introduction to Computer Pointer Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n"
     ]
    }
   ],
   "source": [
    "%env PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel_devcloud_support'))\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qarpo.demoutils import *\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     29      properties = idc001skl,compnode,iei,tank-870,openvino2020.4,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe\r\n",
      "      8      properties = idc002mx8,compnode,iei,tank-870,openvino2020.4,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,hddl-r,iei-mustang-v100-mx8\r\n",
      "     12      properties = idc003a10,compnode,iei,tank-870,openvino2020.4,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,hddl-f,iei-mustang-f100-a10\r\n",
      "     12      properties = idc004nc2,compnode,iei,tank-870,openvino2020.4,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,ncs,intel-ncs2\r\n",
      "      6      properties = idc006kbl,compnode,iei,tank-870,openvino2020.4,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      7      properties = idc007xv5,compnode,iei,tank-870,openvino2020.4,intel-xeon,e3-1268l-v5,skylake,intel-hd-p530,ram32gb,net1gbe\r\n",
      "      8      properties = idc008u2g,compnode,up-squared,grove,openvino2020.4,intel-atom,e3950,apollo-lake,intel-hd-505,ram4gb,net1gbe,ncs,intel-ncs2\r\n",
      "      1      properties = idc009jkl,compnode,jwip,openvino2020.4,intel-core,i5-7500,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      1      properties = idc010jal,compnode,jwip,openvino2020.4,intel-celeron,j3355,apollo-lake,intel-hd-500,ram4gb,net1gbe\r\n",
      "      1      properties = idc011ark2250s,compnode,advantech,openvino2020.4,intel-core,i5-6442eq,skylake,intel-hd-530,ram8gb,net1gbe\r\n",
      "      1      properties = idc012ark1220l,compnode,advantech,openvino2020.4,intel-atom,e3940,apollo-lake,intel-hd-500,ram4gb,net1gbe\r\n",
      "      1      properties = idc013ds580,compnode,advantech,openvino2020.4,intel-atom,e3950,apollo-lake,intel-hd-505,ram2gb,net1gbe\r\n",
      "     11      properties = idc014upxa10fx1,compnode,aaeon,upx-edgei7,openvino2020.4,intel-core,i7-8665ue,whiskey-lake,intel-uhd-620,ram16gb,net1gbe,vpu,myriadx-ma2485\r\n",
      "      2      properties = idc015ai5,compnode,advantech,epc-c301evk-s6a1,openvino2020.4,intel-core,i5-8365ue,whiskey-lake,ram8gb,net1gbe,vpu,myriad,x,ma2485\r\n",
      "      4      properties = idc015ai5,compnode,advantech,epc-c301i5,openvino2020.4,intel-core,i5-8365ue,whiskey-lake,intel-uhd-620,ram8gb,net1gbe,vpu,myriadx-ma2485\r\n",
      "      4      properties = idc016ai7,compnode,advantech,epc-c301i7,openvino2020.4,intel-core,i7-8665ue,whiskey-lake,intel-uhd-620,ram16gb,net1gbe,vpu,myriadx-ma2485\r\n",
      "      1      properties = idc017,compnode,colfax,cx-e4150s-x7,openvino2020.4,intel-xeon,gold5220r,cascade-lake-r,ram96gb,net1gbe\r\n",
      "      1      properties = idc018,compnode,colfax,cx-e4150s-x7,openvino2020.4,intel-xeon,gold6258r,cascade-lake-r,ram96gb,net1gbe\r\n",
      "      1      properties = idc019,compnode,colfax,cx-e4150s-x7,openvino2020.4,intel-xeon,bronze3206r,cascade-lake-r,ram48gb,net1gbe\r\n",
      "      2      properties = idc021,compnode,colfax,cx-e4150s-x7,openvino2020.4,intel-xeon,silver4214r,cascade-lake-r,ram48gb,net1gbe\r\n",
      "     10      properties = idc021,compnode,intel,nuc10fnh,openvino2020.4,intel-i7-10thgen,ram16gb,net1gbe\r\n",
      "      1      properties = idc024,compnode,colfax,cx-e4150s-x7,openvino2020.4,intel-xeon,gold5220r,cascade-lake-r,ram96gb,net1gbe,hddl-r,iei-mustang-v100-mx8\r\n",
      "      1      properties = idc025,compnode,colfax,cx-e4150s-x7,openvino2020.4,intel-xeon,gold6258r,cascade-lake-r,ram96gb,net1gbe,hddl-r,iei-mustang-v100-mx8\r\n",
      "      1      properties = idc026,compnode,colfax,cx-e4150s-x7,openvino2020.4,intel-xeon,bronze3206r,cascade-lake-r,ram48gb,net1gbe,hddl-r,iei-mustang-v100-mx8\r\n",
      "      1      properties = idc027,compnode,colfax,cx-e4150s-x7,openvino2020.4,intel-xeon,silver4214r,cascade-lake-r,ram48gb,net1gbe,hddl-r,iei-mustang-v100-mx8\r\n"
     ]
    }
   ],
   "source": [
    "!pbsnodes | grep compnode | sort | uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_job_completion_print_results(job_name, job_id):\n",
    "    if job_id:\n",
    "        print(\"Waiting for job {} to complete .\".format(job_id), end=\"\")\n",
    "        output_file = \"{}.o{}\".format(job_name, job_id[0].split(\".\")[0])\n",
    "        error_file = \"{}.e{}\".format(job_name, job_id[0].split(\".\")[0])\n",
    "        while not os.path.exists(output_file):  # Wait until the file report is created.\n",
    "            time.sleep(1)\n",
    "            print(\".\", end=\"\")\n",
    "        print(\"Done!\")\n",
    "        !cat $output_file | grep -e \"FpsCounter\" -e \"FPSCounter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading OpenVINOâ„¢ models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading models ||################\n",
      "\n",
      "========== Downloading ../models/intel/face-detection-adas-binary-0001/FP32-INT1/face-detection-adas-binary-0001.xml\n",
      "... 100%, 113 KB, 76415 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/face-detection-adas-binary-0001/FP32-INT1/face-detection-adas-binary-0001.bin\n",
      "... 100%, 1797 KB, 23383 KB/s, 0 seconds passed\n",
      "\n",
      "################|| Post-processing ||################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download File name - face-detection-adas-binary-0001\n",
    "# Download File path - model \n",
    "!python3 /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name face-detection-adas-binary-0001 --output_dir ../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading models ||################\n",
      "\n",
      "========== Downloading ../models/intel/face-detection-adas-0001/FP32/face-detection-adas-0001.xml\n",
      "... 100%, 219 KB, 111367 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/face-detection-adas-0001/FP32/face-detection-adas-0001.bin\n",
      "... 100%, 4113 KB, 19967 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/face-detection-adas-0001/FP16/face-detection-adas-0001.xml\n",
      "... 100%, 219 KB, 139379 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/face-detection-adas-0001/FP16/face-detection-adas-0001.bin\n",
      "... 100%, 2056 KB, 21693 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml\n",
      "... 100%, 510 KB, 140223 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.bin\n",
      "... 100%, 1074 KB, 25974 KB/s, 0 seconds passed\n",
      "\n",
      "################|| Post-processing ||################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download File name - face-detection-adas-binary-0001\n",
    "# Download File path - model \n",
    "!python3 /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name face-detection-adas-0001 --output_dir ../models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landmarks Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading models ||################\n",
      "\n",
      "========== Downloading ../models/intel/landmarks-regression-retail-0009/FP32/landmarks-regression-retail-0009.xml\n",
      "... 100%, 41 KB, 61322 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/landmarks-regression-retail-0009/FP32/landmarks-regression-retail-0009.bin\n",
      "... 100%, 744 KB, 24556 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/landmarks-regression-retail-0009/FP16/landmarks-regression-retail-0009.xml\n",
      "... 100%, 41 KB, 82080 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/landmarks-regression-retail-0009/FP16/landmarks-regression-retail-0009.bin\n",
      "... 100%, 372 KB, 37056 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/landmarks-regression-retail-0009/FP16-INT8/landmarks-regression-retail-0009.xml\n",
      "... 100%, 75 KB, 100373 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/landmarks-regression-retail-0009/FP16-INT8/landmarks-regression-retail-0009.bin\n",
      "... 100%, 239 KB, 41401 KB/s, 0 seconds passed\n",
      "\n",
      "################|| Post-processing ||################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download File name - landmarks-regression-retail-0009\n",
    "# Download File path - model \n",
    "!python3 /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name landmarks-regression-retail-0009 --output_dir ../models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head Pose Estimation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading models ||################\n",
      "\n",
      "========== Downloading ../models/intel/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001.xml\n",
      "... 100%, 49 KB, 59437 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001.bin\n",
      "... 100%, 7468 KB, 18571 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml\n",
      "... 100%, 49 KB, 88140 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.bin\n",
      "... 100%, 3734 KB, 15621 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/head-pose-estimation-adas-0001/FP16-INT8/head-pose-estimation-adas-0001.xml\n",
      "... 100%, 81 KB, 88472 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/head-pose-estimation-adas-0001/FP16-INT8/head-pose-estimation-adas-0001.bin\n",
      "... 100%, 2026 KB, 25043 KB/s, 0 seconds passed\n",
      "\n",
      "################|| Post-processing ||################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download File name - head-pose-estimation-adas-0001\n",
    "# Download File path - model \n",
    "!python3 /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name head-pose-estimation-adas-0001 --output_dir ../models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaze Estimation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading models ||################\n",
      "\n",
      "========== Downloading ../models/intel/gaze-estimation-adas-0002/FP32/gaze-estimation-adas-0002.xml\n",
      "... 100%, 64 KB, 80272 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/gaze-estimation-adas-0002/FP32/gaze-estimation-adas-0002.bin\n",
      "... 100%, 7352 KB, 28068 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/gaze-estimation-adas-0002/FP16/gaze-estimation-adas-0002.xml\n",
      "... 100%, 64 KB, 98597 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/gaze-estimation-adas-0002/FP16/gaze-estimation-adas-0002.bin\n",
      "... 100%, 3676 KB, 28815 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/gaze-estimation-adas-0002/FP16-INT8/gaze-estimation-adas-0002.xml\n",
      "... 100%, 138 KB, 111905 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading ../models/intel/gaze-estimation-adas-0002/FP16-INT8/gaze-estimation-adas-0002.bin\n",
      "... 100%, 2008 KB, 29305 KB/s, 0 seconds passed\n",
      "\n",
      "################|| Post-processing ||################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download File name - gaze-estimation-adas-0002\n",
    "# Download File path - model \n",
    "!python3 /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name gaze-estimation-adas-0002 --output_dir ../models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Input Video</h2>\n",
       "    \n",
       "    <video alt=\"\" controls autoplay muted height=\"480\"><source src=\"../bin/demo.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ln -sf ../bin/demo.mp4 \n",
    "videoHTML('Input Video', ['../bin/demo.mp4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Profiler for Computer Pointer Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Inference on a Video\n",
    "In the next few cells, You'll submit your job using the `qsub` command and retrieve the results for each job. Each of the cells below should submit a job to different edge compute nodes.\n",
    "\n",
    "The output of the cell is the `JobID` of your job, which you can use to track progress of a job with `liveQStat`.\n",
    "\n",
    "You will need to submit a job for each of the following hardware types:\n",
    "* **CPU**\n",
    "* **GPU**\n",
    "* **VPU**\n",
    "* **FPGA**\n",
    "\n",
    "**Note:** You will have to submit each job one at a time and retrieve their results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u45445/My-Notebooks/Computer-Pointer-Controller/notebook\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1. Create the Python Script.ipynb'\t\t input_feeder.py\r\n",
      "'2. Create Job Submission Script.ipynb'\t\t landmark_detection.py\r\n",
      " 3.Computer_Pointer_Controller_Benchmark.ipynb\t main.py\r\n",
      " demo.mp4\t\t\t\t\t mouse_controller.py\r\n",
      " face_detection.py\t\t\t\t mouse_process.py\r\n",
      " gaze_Estimation.py\t\t\t\t queue_job.sh\r\n",
      " head_postion_estimation.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogui\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/69/c8b0cab7cbc6badbc0079392e5d4b50f3e4be63e0091f0f414bd1ea4ac07/PyAutoGUI-0.9.50.tar.gz\n",
      "Collecting pymsgbox (from pyautogui)\n",
      "  Using cached https://files.pythonhosted.org/packages/e0/d5/148383b342b621a23cb340e7b378122d3fd53a631c5e5142a5c869bdfa5b/PyMsgBox-1.0.8.tar.gz\n",
      "Collecting PyTweening>=1.0.1 (from pyautogui)\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/f8/c32a58d6e4dff8aa5c27e907194d69f3b57e525c2e4af96f39c6e9c854d2/PyTweening-1.0.3.zip\n",
      "Collecting pyscreeze>=0.1.21 (from pyautogui)\n",
      "  Using cached https://files.pythonhosted.org/packages/b7/7d/a0e85da28a96e2ff2f39e682ff84eb92501b564883fde87d92aee29966a2/PyScreeze-0.1.26.tar.gz\n",
      "Collecting pygetwindow>=0.0.5 (from pyautogui)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/8b/f1a396f8ec5923e11246fabe29419a6dd8949a0360337fe6ad0f28a9c33b/PyGetWindow-0.0.8.tar.gz\n",
      "Collecting mouseinfo (from pyautogui)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/fa/b2ba8229b9381e8f6381c1dcae6f4159a7f72349e414ed19cfbbd1817173/MouseInfo-0.1.3.tar.gz\n",
      "Collecting python3-Xlib (from pyautogui)\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/c6/2c5999de3bb1533521f1101e8fe56fd9c266732f4d48011c7c69b29d12ae/python3-xlib-0.15.tar.gz (132kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 2.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting Pillow>=4.0.0 (from pyscreeze>=0.1.21->pyautogui)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/30/bf/92385b4262178ca22b34f82e0e09c2922eb351fe39f3cc7b8ba9ea555b41/Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.2MB 406kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyrect (from pygetwindow>=0.0.5->pyautogui)\n",
      "Collecting pyperclip (from mouseinfo->pyautogui)\n",
      "  Using cached https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
      "Building wheels for collected packages: pyautogui, pymsgbox, PyTweening, pyscreeze, pygetwindow, mouseinfo, python3-Xlib, pyperclip\n",
      "  Running setup.py bdist_wheel for pyautogui ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/u45445/.cache/pip/wheels/e9/4d/ab/55251d5f40fc314e859ceb9a1ef9f87dbbeb232b7c7ecf7639\n",
      "  Running setup.py bdist_wheel for pymsgbox ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/u45445/.cache/pip/wheels/c4/70/12/47ad53247da7e814e180a8361612b17bab8f7b9aa071318695\n",
      "  Running setup.py bdist_wheel for PyTweening ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/u45445/.cache/pip/wheels/7b/92/30/06e21159eed2709436bfb6d7c690959e578cf74f029643866e\n",
      "  Running setup.py bdist_wheel for pyscreeze ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/u45445/.cache/pip/wheels/d4/a5/e1/d06a3ae91e6c66ab67d540c215bc2a0da99155c1281e8c921e\n",
      "  Running setup.py bdist_wheel for pygetwindow ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/u45445/.cache/pip/wheels/a7/20/2c/7ba9c02521960b138ff4a635fced58cb7a3bc3cc99d52f56b5\n",
      "  Running setup.py bdist_wheel for mouseinfo ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/u45445/.cache/pip/wheels/eb/81/32/4d7b345486dbc3f3ee45316f8f4cbdebafc1b5d1da3353b529\n",
      "  Running setup.py bdist_wheel for python3-Xlib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/u45445/.cache/pip/wheels/e9/be/31/bebab5ac079cfa8305381fa6ee15ea142eade1fec0c71e1278\n",
      "  Running setup.py bdist_wheel for pyperclip ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/u45445/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
      "Successfully built pyautogui pymsgbox PyTweening pyscreeze pygetwindow mouseinfo python3-Xlib pyperclip\n",
      "Installing collected packages: pymsgbox, PyTweening, Pillow, pyscreeze, pyrect, pygetwindow, pyperclip, python3-Xlib, mouseinfo, pyautogui\n",
      "Successfully installed Pillow-7.2.0 PyTweening-1.0.3 mouseinfo-0.1.3 pyautogui-0.9.50 pygetwindow-0.0.8 pymsgbox-1.0.8 pyperclip-1.8.0 pyrect-0.1.4 pyscreeze-0.1.26 python3-Xlib-0.15\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DISPLAY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-fa2587ca3a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyautogui\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyautogui/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmouseinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmouseInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/mouseinfo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DISPLAY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_linuxPosition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DISPLAY'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h] -i INPUT -m_fd MODEL_FACE_DETECTION\r\n",
      "               [-d_fd {CPU,GPU,FPGA,MYRIAD,HETERO,HDDL}] [-t_fd [0..1]]\r\n",
      "               [-o_fd] -m_hp MODEL_HEAD_POSITION\r\n",
      "               [-d_hp {CPU,GPU,FPGA,MYRIAD,HETERO,HDDL}] [-o_hp] -m_lm\r\n",
      "               MODEL_LANDMARK_REGRESSOR\r\n",
      "               [-d_lm {CPU,GPU,FPGA,MYRIAD,HETERO,HDDL}] [-o_lm] -m_gm\r\n",
      "               MODEL_GAZE [-d_gm {CPU,GPU,FPGA,MYRIAD,HETERO,HDDL}] [-o_gm]\r\n",
      "               [-o_mc] [-pc] [-exp_r_fd NUMBER] [-cw CROP_WIDTH]\r\n",
      "               [-ch CROP_HEIGHT] [-v] [-l PATH] [-c PATH] [-tl] [-o PATH]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -i INPUT, --input INPUT\r\n",
      "                        Path to image or video file in .mp4 format or enter\r\n",
      "                        CAM for webcam\r\n",
      "  -m_fd MODEL_FACE_DETECTION, --model_face_detection MODEL_FACE_DETECTION\r\n",
      "                        Path to load an .xml file with a trained Face\r\n",
      "                        Detection model\r\n",
      "  -d_fd {CPU,GPU,FPGA,MYRIAD,HETERO,HDDL}\r\n",
      "                        (optional) Target device for the Face Detection model\r\n",
      "                        device selection (default: CPU)\r\n",
      "  -t_fd [0..1]          (optional) Set the Probability threshold for face\r\n",
      "                        detections(default: 0.4)\r\n",
      "  -o_fd                 (optional) Process the face detection output\r\n",
      "  -m_hp MODEL_HEAD_POSITION, --model_head_position MODEL_HEAD_POSITION\r\n",
      "                        Path to load an .xml file with a trained Head Pose\r\n",
      "                        Estimation model\r\n",
      "  -d_hp {CPU,GPU,FPGA,MYRIAD,HETERO,HDDL}\r\n",
      "                        (optional) Target device for the Head Position model\r\n",
      "                        (default: CPU)\r\n",
      "  -o_hp                 (optional) Show Head Position output\r\n",
      "  -m_lm MODEL_LANDMARK_REGRESSOR, --model_landmark_regressor MODEL_LANDMARK_REGRESSOR\r\n",
      "                        Path to load an .xml file with a trained Head Pose\r\n",
      "                        Estimation model\r\n",
      "  -d_lm {CPU,GPU,FPGA,MYRIAD,HETERO,HDDL}\r\n",
      "                        (optional) Target device for the Facial Landmarks\r\n",
      "                        Regression model (default: CPU)\r\n",
      "  -o_lm                 (optional) Show Landmark detection output\r\n",
      "  -m_gm MODEL_GAZE, --model_gaze MODEL_GAZE\r\n",
      "                        Path to an .xml file with a trained Gaze Estimation\r\n",
      "                        model\r\n",
      "  -d_gm {CPU,GPU,FPGA,MYRIAD,HETERO,HDDL}\r\n",
      "                        (optional) Target device for the Gaze estimation model\r\n",
      "                        (default: CPU)\r\n",
      "  -o_gm                 (optional) Show Gaze estimation output\r\n",
      "  -o_mc                 (optional) Run mouse counter\r\n",
      "  -pc, --perf_stats     (optional) Output detailed per-layer performance stats\r\n",
      "  -exp_r_fd NUMBER      (optional) Scaling ratio for bboxes passed to face\r\n",
      "                        recognition (default: 1.2)\r\n",
      "  -cw CROP_WIDTH, --crop_width CROP_WIDTH\r\n",
      "                        (optional) Crop the input stream to this width\r\n",
      "                        (default: no crop). Both -cw and -ch parameters should\r\n",
      "                        be specified to use crop.\r\n",
      "  -ch CROP_HEIGHT, --crop_height CROP_HEIGHT\r\n",
      "                        (optional) Crop the input stream to this width\r\n",
      "                        (default: no crop). Both -cw and -ch parameters should\r\n",
      "                        be specified to use crop.\r\n",
      "  -v, --verbose         (optional) Be more verbose\r\n",
      "  -l PATH, --cpu_lib PATH\r\n",
      "                        (optional) For MKLDNN (CPU)-targeted custom layers, if\r\n",
      "                        any. Path to a shared library with custom layers\r\n",
      "                        implementations\r\n",
      "  -c PATH, --gpu_lib PATH\r\n",
      "                        (optional) For clDNN (GPU)-targeted custom layers, if\r\n",
      "                        any. Path to the XML file with descriptions of the\r\n",
      "                        kernels\r\n",
      "  -tl, --timelapse      (optional) Auto-pause after each frame\r\n",
      "  -o PATH, --output PATH\r\n",
      "                        (optional) Path to save the output video to\r\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1. Create the Python Script.ipynb'\t\t ie_module.py\r\n",
      "'2. Create Job Submission Script.ipynb'\t\t ie_module.pyc\r\n",
      " 3.Computer_Pointer_Controller_Benchmark.ipynb\t input_feeder.py\r\n",
      " demo.mp4\t\t\t\t\t landmark_detection.py\r\n",
      " face_detection.py\t\t\t\t main.py\r\n",
      " gaze_Estimation.py\t\t\t\t mouse_controller.py\r\n",
      " gaze_Estimator.py\t\t\t\t mouse_process.py\r\n",
      " head_postion_estimation.py\t\t\t __pycache__\r\n",
      " helper.py\t\t\t\t\t queue_job.sh\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_job_id = !qsub queue_job.sh -d . -l nodes=1:tank-870:i5-6500te -F '../models/intel/face-detection-adas-0001/FP16/face-detection-adas-0001 ../models/intel/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001  ../models/intel/landmarks-regression-retail-0009/FP16/landmarks-regression-retail-0009 ../models/intel/gaze-estimation-adas-0002/FP16/gaze-estimation-adas-0002 CPU CPU CPU CPU' -N store_core "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6e3bb61225461786f2aa66bc73be2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid gray', height='300px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df5cfc757b54a2e86587f00e76d6887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Stop', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "liveQstat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar zxf output.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: stdout.log: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat stdout.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-95-7cd70c96f98d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-95-7cd70c96f98d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python main.py -i '../bin/demo.mp4' -m_fd '../models/intel/face-detection-adas-0001/FP16/face-detection-adas-0001.xml' -m_hp '../models/intel/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml' -m_lm '../models/intel/landmarks-regression-retail-0009/FP16/landmarks-regression-retail-0009.xml' -m_gm '../models/intel/gaze-estimation-adas-0002/FP16/gaze-estimation-adas-0002.xml' -d_fd 'MYRIAD' -d_hp 'MYRIAD' -d_lm 'MYRIAD' -d_gm 'MYRIAD'\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python main.py -i '../bin/demo.mp4' -m_fd '../models/intel/face-detection-adas-0001/FP16/face-detection-adas-0001.xml' -m_hp '../models/intel/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml' -m_lm '../models/intel/landmarks-regression-retail-0009/FP16/landmarks-regression-retail-0009.xml' -m_gm '../models/intel/gaze-estimation-adas-0002/FP16/gaze-estimation-adas-0002.xml' -d_fd 'MYRIAD' -d_hp 'MYRIAD' -d_lm 'MYRIAD' -d_gm 'MYRIAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from head_postion_estimation import Head_Pose_Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../bin/demo.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set the model path according to the precision (FP32/FP16/INT8) \n",
    "def set_model_path(precision):\n",
    "    if precision == 'FP32':\n",
    "        FACEMODELPATH=\"../models/intel/face-detection-adas-0001/FP32/face-detection-adas-0001\"\n",
    "        POSEMODELPATH=\"../models/intel/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001\"\n",
    "        LANDMARKSMODELPATH=\"../models/intel/landmarks-regression-retail-0009/FP32/landmarks-regression-retail-0009\"   \n",
    "        GAZEMODELPATH=\"../models/intel/gaze-estimation-adas-0002/FP32/gaze-estimation-adas-0002\" \n",
    "    elif precision == 'FP16':\n",
    "        FACEMODELPATH=\"../models/intel/face-detection-adas-0001/FP16/face-detection-adas-0001\"\n",
    "        POSEMODELPATH=\"../models/intel/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001\"\n",
    "        LANDMARKSMODELPATH=\"../models/intel/landmarks-regression-retail-0009/FP16/landmarks-regression-retail-0009\"   \n",
    "        GAZEMODELPATH=\"../models/intel/gaze-estimation-adas-0002/FP16/gaze-estimation-adas-0002\"\n",
    "    elif precision == 'INT8':\n",
    "        FACEMODELPATH=\"../models/intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001\"\n",
    "        POSEMODELPATH=\"../models/intel/head-pose-estimation-adas-0001/FP16-INT8/head-pose-estimation-adas-0001\"\n",
    "        LANDMARKSMODELPATH=\"../models/intel/landmarks-regression-retail-0009/FP16-INT8/landmarks-regression-retail-0009\"    \n",
    "        GAZEMODELPATH=\"../models/intel/gaze-estimation-adas-0002/FP16-INT8/gaze-estimation-adas-0002\"\n",
    "    else:\n",
    "        FACEMODELPATH, POSEMODELPATH, LANDMARKSMODELPATH, GAZEMODELPATH = [], [], [], []\n",
    "        raise ValueError(\"Specify a suitable precision: FP32, FP16 or INT8\")\n",
    "        \n",
    "    return FACEMODELPATH, POSEMODELPATH, LANDMARKSMODELPATH, GAZEMODELPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set the output for the stats file\n",
    "def set_output_path(device, precision):\n",
    "    output_path = \"./performance/\" + device + \"/\" + precision + \".txt\"\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create command to run\n",
    "def create_command(device, fm, pm, lm, gm, o, i):\n",
    "    if device == 'NCS2':\n",
    "        device = 'MYRIAD'\n",
    "    cmd = \"python3 main.py -fm \" + fm + \" -pm \" + pm + \" -lm \" + lm + \" -gm \" + gm + \" -i \" + i + \" -o_stats \" + o + \" -d \" + device\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'CPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create command to generate stats\n",
    "precision = 'FP32'\n",
    "FACEMODELPATH, POSEMODELPATH, LANDMARKSMODELPATH, GAZEMODELPATH = set_model_path(precision)\n",
    "OUTPUTSTATS = set_output_path(device, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python3 main.py -fm ../models/intel/face-detection-adas-0001/FP32/face-detection-adas-0001 -pm ../models/intel/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001 -lm ../models/intel/landmarks-regression-retail-0009/FP32/landmarks-regression-retail-0009 -gm ../models/intel/gaze-estimation-adas-0002/FP32/gaze-estimation-adas-0002 -i ../bin/demo.mp4 -o_stats ./performance/CPU/FP32.txt -d CPU'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_command(device, FACEMODELPATH, POSEMODELPATH, LANDMARKSMODELPATH, GAZEMODELPATH, OUTPUTSTATS, input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create command to generate stats\n",
    "precision = 'FP16'\n",
    "FACEMODELPATH, POSEMODELPATH, LANDMARKSMODELPATH, GAZEMODELPATH = set_model_path(precision)\n",
    "OUTPUTSTATS = set_output_path(device, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python3 main.py -fm ../models/intel/face-detection-adas-0001/FP16/face-detection-adas-0001 -pm ../models/intel/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001 -lm ../models/intel/landmarks-regression-retail-0009/FP16/landmarks-regression-retail-0009 -gm ../models/intel/gaze-estimation-adas-0002/FP16/gaze-estimation-adas-0002 -i ../bin/demo.mp4 -o_stats ./performance/CPU/FP16.txt -d CPU'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_command(device, FACEMODELPATH, POSEMODELPATH, LANDMARKSMODELPATH, GAZEMODELPATH, OUTPUTSTATS, input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create command to generate stats\n",
    "precision = 'INT8'\n",
    "FACEMODELPATH, POSEMODELPATH, LANDMARKSMODELPATH, GAZEMODELPATH = set_model_path(precision)\n",
    "OUTPUTSTATS = set_output_path(device, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python3 main.py -fm ../models/intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001 -pm ../models/intel/head-pose-estimation-adas-0001/FP16-INT8/head-pose-estimation-adas-0001 -lm ../models/intel/landmarks-regression-retail-0009/FP16-INT8/landmarks-regression-retail-0009 -gm ../models/intel/gaze-estimation-adas-0002/FP16-INT8/gaze-estimation-adas-0002 -i ../bin/demo.mp4 -o_stats ./performance/CPU/INT8.txt -d CPU'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_command(device, FACEMODELPATH, POSEMODELPATH, LANDMARKSMODELPATH, GAZEMODELPATH, OUTPUTSTATS, input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'NCS2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create command to generate stats\n",
    "precision = 'FP16'\n",
    "FACEMODELPATH, POSEMODELPATH, LANDMARKSMODELPATH, GAZEMODELPATH = set_model_path(precision)\n",
    "OUTPUTSTATS = set_output_path(device, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_command(device, FACEMODELPATH, POSEMODELPATH, LANDMARKSMODELPATH, GAZEMODELPATH, OUTPUTSTATS, input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CPU/FP32.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-ba797b49eb46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstats_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Open file and get data out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmodel_load_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minference_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CPU/FP32.txt'"
     ]
    }
   ],
   "source": [
    "# CPU performance data\n",
    "precisions = ['FP32', 'FP16', 'INT8']\n",
    "model_load_time=[]\n",
    "inference_time=[]\n",
    "fps=[]\n",
    "\n",
    "for prec in precisions:\n",
    "    stats_path = set_output_path('CPU', prec)\n",
    "    stats_file = stats_path.split(\"/\", maxsplit=2)[2]\n",
    "    # Open file and get data out\n",
    "    with open(stats_file, 'r') as f:\n",
    "        model_load_time.append(float(f.readline().split(\"\\n\")[0].split(\" \")[4]))\n",
    "        inference_time.append(float(f.readline().split(\"\\n\")[0].split(\" \")[4]))\n",
    "        fps.append(float(f.readline().split(\"\\n\")[0].split(\" \")[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot data\n",
    "\n",
    "def add_bar_labels(plot, axis):\n",
    "    for value in plot:\n",
    "        height = value.get_height()\n",
    "        axis.text(value.get_x() + value.get_width()/2.,\n",
    "             1.007*height,'%.2f' % height, ha='center', va='bottom')\n",
    "\n",
    "fig, (ax1, ax2, ax3) =  plt.subplots(nrows=1, ncols=3, figsize=(16,5))\n",
    "\n",
    "p1 = ax1.bar(precisions, inference_time)\n",
    "ax1.set_title(\"CPU Inference Time (s)\", fontweight='bold')\n",
    "add_bar_labels(p1, ax1)\n",
    "\n",
    "p2 = ax2.bar(precisions, model_load_time)\n",
    "ax2.set_title(\"CPU Models Loading Time (s)\", fontweight='bold')\n",
    "add_bar_labels(p2, ax2)\n",
    "\n",
    "p3 = ax3.bar(precisions, fps)\n",
    "ax3.set_title(\"CPU Frames Per Second (fps)\", fontweight='bold')\n",
    "add_bar_labels(p3, ax3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(\"cpu_performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
